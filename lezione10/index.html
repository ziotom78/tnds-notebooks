<!doctype html> <html lang=en > <meta charset=UTF-8 > <meta name=viewport  content="width=device-width, initial-scale=1"> <link rel=stylesheet  href="/tnds-notebooks/libs/katex/katex.min.css"> <link rel=stylesheet  href="/tnds-notebooks/libs/highlight/github.min.css"> <link rel=stylesheet  href="/tnds-notebooks/css/franklin.css"> <link rel=stylesheet  href="/tnds-notebooks/css/poole_hyde.css"> <style> html {font-size: 17px;} .franklin-content {position: relative; padding-left: 8%; padding-right: 5%; line-height: 1.35em;} @media (min-width: 940px) { .franklin-content {width: 100%; margin-left: auto; margin-right: auto;} } @media (max-width: 768px) { .franklin-content {padding-left: 6%; padding-right: 6%;} } </style> <link rel=icon  href="/tnds-notebooks/assets/favicon.png"> <title>Lezioni 10 e 11</title> <div class=sidebar > <div class="container sidebar-sticky"> <div class=sidebar-about > <h1><a href="/tnds-notebooks/">TNDS</a></h1> <p class=lead >Prof. M.&nbsp;Tomasi</p> </div> <nav class=sidebar-nav > <a class="sidebar-nav-item " href="/tnds-notebooks/">Home</a> <a class="sidebar-nav-item " href="/tnds-notebooks/lezione07/">Lezione 07</a> <a class="sidebar-nav-item " href="/tnds-notebooks/lezione08/">Lezione 08</a> <a class="sidebar-nav-item active" href="/tnds-notebooks/lezione10/">Lezioni 10 e 11</a> </nav> <p>&copy; Maurizio Tomasi.</p> </div> </div> <div class="content container"> <div class=franklin-content > <p>Dal momento che la lezione 11 richiede di impiegare i codici sviluppati nella lezione 10, presento gli esercizi delle due lezioni in un&#39;unica pagina.</p> <p><div class=franklin-toc ><ol><li><a href="#esercizio_101">Esercizio 10.1</a><ol><li><a href="#generatore_lineare_congruenziale">Generatore Lineare Congruenziale</a><li><a href="#distribuzione_esponenziale">Distribuzione esponenziale</a><li><a href="#distribuzione_gaussiana">Distribuzione Gaussiana</a><li><a href="#distribuzione_gaussiana_con_metodo_accept-reject">Distribuzione Gaussiana con metodo Accept-Reject</a></ol><li><a href="#esercizio_102">Esercizio 10.2</a><li><a href="#esercizio_110">Esercizio 11.0</a><li><a href="#esercizio_111">Esercizio 11.1</a></ol></div> </p> <p>Iniziamo importando i pacchetti che ci serviranno.</p> <pre><code class=language-julia >using Printf
using Plots
using Statistics</code></pre> <h2 id=esercizio_101 ><a href="#esercizio_101" class=header-anchor >Esercizio 10.1</a></h2> <p>In Julia non esiste il concetto di «classe», ma esistono le <code>struct</code> che funzionano in modo concettualmente simile. Non permettono di associare metodi, tranne eventualmente un semplice costruttore. Definiamo una classe <code>GLC</code> che sia equivalente alla classe <code>Random</code> che vi viene richiesto di implementare in C&#43;&#43;.</p> <h3 id=generatore_lineare_congruenziale ><a href="#generatore_lineare_congruenziale" class=header-anchor >Generatore Lineare Congruenziale</a></h3> <pre><code class=language-julia >mutable struct GLC
    a::UInt64
    c::UInt64
    m::UInt64
    seed::UInt64

    GLC&#40;myseed&#41; &#61; new&#40;1664525, 1013904223, 1 &lt;&lt; 31, myseed&#41;
end</code></pre> <p>Definiamo ora una funzione <code>rand</code> che restituisca un numero casuale floating-point compreso in un intervallo:</p> <pre><code class=language-julia >@doc &quot;&quot;&quot;
    rand&#40;glc::GLC, xmin, xmax&#41;

Return a pseudo-random number uniformly distributed in the
interval &#91;xmin, xmax&#41;.
&quot;&quot;&quot;
function rand&#40;glc::GLC, xmin, xmax&#41;
    glc.seed &#61; &#40;glc.a * glc.seed &#43; glc.c&#41; &#37; glc.m
    xmin &#43; &#40;xmax - xmin&#41; * glc.seed / glc.m
end</code></pre><pre><code class="plaintext code-output">rand</code></pre>
<p>È molto comodo avere anche una funzione <code>rand</code> che usi l&#39;intervallo \([0, 1]\).</p>
<pre><code class=language-julia >@doc &quot;&quot;&quot;
    rand&#40;glc::GLC&#41;

Return a pseudo-random number uniformly distributed in the
interval &#91;0, 1&#41;.
&quot;&quot;&quot;
rand&#40;glc::GLC&#41; &#61; rand&#40;glc, 0.0, 1.0&#41;</code></pre><pre><code class="plaintext code-output">rand</code></pre>
<p>Le funzioni definite sopra forniscono una guida, definita dalla macro <code>@doc</code> e invocabile dalla REPL col carattere <code>?</code> seguito dal nome della funzione:</p>
<pre><code class=language-julia >julia&gt; ?randgauss</code></pre>
<p>Questi sono i numeri che dovreste aspettarvi se avete implementato bene il vostro codice &#40;notate che i numeri cambiano se usate un seed diverso&#33;&#41;.</p>
<pre><code class=language-julia >glc &#61; GLC&#40;1&#41;
for i in 1:5
    println&#40;i, &quot;: &quot;, rand&#40;glc&#41;&#41;
end</code></pre><pre><code class="plaintext code-output">1: 0.47291105054318905
2: 0.7385413474403322
3: 0.008484064601361752
4: 0.40976652735844254
5: 0.10108725726604462
</code></pre>
<p>Preoccupatevi quindi di creare una serie di <code>assert</code> nel vostro codice C&#43;&#43; che verifichino che ottenete gli stessi valori se partite dallo stesso seme &#40;<code>1</code>&#41;, possibilmente in una funzione <code>test_random_numbers&#40;&#41;</code> invocata all&#39;inizio del vostro <code>main</code>.</p>
<p>Quando si implementano numeri pseudo-casuali, è sempre bene farsi un&#39;idea della distribuzione dei valori. Disegnamo quindi l&#39;istogramma della distribuzione di un gran numero di campioni, e verifichiamo che siano uniformemente distribuiti nell&#39;intervallo &#91;0, 1&#41;.</p>
<pre><code class=language-julia >histogram&#40;&#91;rand&#40;glc&#41; for i in 1:10000&#93;, label&#61;&quot;&quot;&#41;</code></pre>
<img src="/tnds-notebooks/assets/lezione10/code/output/rand_hist.svg" alt="">
<h3 id=distribuzione_esponenziale ><a href="#distribuzione_esponenziale" class=header-anchor >Distribuzione esponenziale</a></h3>
<p>Trattandosi di una formula semplice, in Julia si può definire <code>randexp</code> con una sola riga di codice:</p>
<pre><code class=language-julia >&quot;&quot;&quot;
    randexp&#40;glc::GLC&#41;

Return a positive pseudo-random number distributed with a
probability density &#96;&#96;p&#40;x&#41; &#61; λ e^&#123;-λ x&#125;&#96;&#96;.
&quot;&quot;&quot;
randexp&#40;glc::GLC, λ&#41; &#61; -log&#40;1 - rand&#40;glc&#41;&#41; / λ</code></pre><pre><code class="plaintext code-output">randexp</code></pre>
<p>Questi sono i numeri per i vostri <code>assert</code>:</p>
<pre><code class=language-julia >glc &#61; GLC&#40;1&#41;
for i in 1:5
    println&#40;i, &quot;: &quot;, randexp&#40;glc, 1&#41;&#41;
end</code></pre><pre><code class="plaintext code-output">1: 0.6403859601352556
2: 1.3414791243855002
3: 0.008520259140710315
4: 0.5272371040158115
5: 0.10656930958385337
</code></pre>
<p>Questo è l&#39;istogramma</p>
<pre><code class=language-julia >histogram&#40;&#91;randexp&#40;glc, 1&#41; for i in 1:10000&#93;, label&#61;&quot;&quot;&#41;</code></pre>
<img src="/tnds-notebooks/assets/lezione10/code/output/randexp_hist.svg" alt="">
<h3 id=distribuzione_gaussiana ><a href="#distribuzione_gaussiana" class=header-anchor >Distribuzione Gaussiana</a></h3>
<pre><code class=language-julia >@doc raw&quot;&quot;&quot;
    randgauss&#40;glc::GLC, μ, σ&#41;

Return a pseudo-random number distributed with a probability
density &#96;&#96;p&#40;x&#41; &#61; \frac&#123;1&#125;&#123;\sqrt&#123;2πσ^2&#125;&#125;
\exp\left&#40;-\frac&#123;&#40;x - μ&#41;^2&#125;&#123;2σ^2&#125;\right&#41;&#96;&#96;, using the
Box-Müller algorithm.
&quot;&quot;&quot;
function randgauss&#40;glc::GLC, μ, σ&#41;
    s &#61; rand&#40;glc&#41;
    t &#61; rand&#40;glc&#41;
    x &#61; sqrt&#40;-2log&#40;1 - s&#41;&#41; * cos&#40;2π * t&#41;
    μ &#43; σ * x
end</code></pre><pre><code class="plaintext code-output">randgauss</code></pre>
<p>Questi sono i numeri per i vostri <code>assert</code>:</p>
<pre><code class=language-julia >glc &#61; GLC&#40;1&#41;
for i in 1:5
    println&#40;i, &quot;: &quot;, randgauss&#40;glc, 2, 1&#41;&#41;
end</code></pre><pre><code class="plaintext code-output">1: 1.9185906933235062
2: 1.8898847197814346
3: 1.9682233298032183
4: 2.960947466486181
5: 1.9538792463229713
</code></pre>
<p>Questo è l&#39;istogramma:</p>
<pre><code class=language-julia >histogram&#40;&#91;randgauss&#40;glc, 2, 1&#41; for i in 1:10000&#93;, label&#61;&quot;&quot;&#41;</code></pre>
<img src="/tnds-notebooks/assets/lezione10/code/output/randgauss_hist.svg" alt="">
<h3 id=distribuzione_gaussiana_con_metodo_accept-reject ><a href="#distribuzione_gaussiana_con_metodo_accept-reject" class=header-anchor >Distribuzione Gaussiana con metodo Accept-Reject</a></h3>
<pre><code class=language-julia >@doc raw&quot;&quot;&quot;
    randgauss_ar&#40;glc::GLC, μ, σ&#41;

Return a pseudo-random number distributed with a probability
density &#96;&#96;p&#40;x&#41; &#61; \frac1&#123;\sqrt&#123;2πσ^2&#125;&#125;
\exp\left&#40;-\frac&#123;&#40;x - μ&#41;^2&#125;&#123;2σ^2&#125;\right&#41;&#96;&#96;, using the
accept-reject algorithm.
&quot;&quot;&quot;
function randgauss_ar&#40;glc::GLC, μ, σ&#41;
    while true  # Loop forever
        x &#61; rand&#40;glc, -5., 5.&#41;
        y &#61; rand&#40;glc&#41;
        g &#61; exp&#40;-x^2 / 2&#41;
        y ≤ g &amp;&amp; return μ &#43; x * σ
    end
end</code></pre><pre><code class="plaintext code-output">randgauss_ar</code></pre>
<p>Questi sono i numeri per gli <code>assert</code>:</p>
<pre><code class=language-julia >glc &#61; GLC&#40;1&#41;
for i in 1:5
    println&#40;i, &quot;: &quot;, randgauss_ar&#40;glc, 2, 1&#41;&#41;
end</code></pre><pre><code class="plaintext code-output">1: 1.7291105054318905
2: 2.4952592495828867
3: 2.009022830054164
4: 0.6520544346421957
5: 1.318840131163597
</code></pre>
<p>Questo è l&#39;istogramma:</p>
<pre><code class=language-julia >histogram&#40;&#91;randgauss_ar&#40;glc, 2, 1&#41; for i in 1:10000&#93;, label&#61;&quot;&quot;&#41;</code></pre>
<img src="/tnds-notebooks/assets/lezione10/code/output/randgauss_ar_hist.svg" alt="">
<h2 id=esercizio_102 ><a href="#esercizio_102" class=header-anchor >Esercizio 10.2</a></h2>
<p>Questa è una semplice implementazione dell&#39;integrale della media:</p>
<pre><code class=language-julia >&quot;&quot;&quot;
    intmean&#40;glc::GLC, fn, a, b, N&#41;

Evaluate the integral of &#96;fn&#40;x&#41;&#96; in the interval &#96;&#96;&#91;a, b&#93;&#96;&#96;
using the mean method with &#96;&#96;N&#96;&#96; points.
&quot;&quot;&quot;
function intmean&#40;glc::GLC, fn, a, b, N&#41;
    &#40;b - a&#41; * sum&#40;&#91;fn&#40;rand&#40;glc, a, b&#41;&#41; for i in 1:N&#93;&#41; / N
end</code></pre><pre><code class="plaintext code-output">intmean</code></pre>
<p>L&#39;integrale <em>hit-or-miss</em> è solo lievemente più complicato:</p>
<pre><code class=language-julia >&quot;&quot;&quot;
    inthm&#40;glc::GLC, fn, a, b, fmax, N&#41;

Evaluate the integral of &#96;fn&#40;x&#41;&#96; in the interval &#96;&#96;&#91;a, b&#93;&#96;&#96;
using the hit-or-miss method with &#96;&#96;N&#96;&#96; points, assuming that
&#96;fn&#40;x&#41;&#96; assumes values in the range &#96;&#91;0, fmax&#93;&#96;.
&quot;&quot;&quot;
function inthm&#40;glc::GLC, fn, a, b, fmax, N&#41;
    hits &#61; 0
    for i in 1:N
        x &#61; rand&#40;glc, a, b&#41;
        y &#61; rand&#40;glc, 0, fmax&#41;
        y ≤ fn&#40;x&#41; &amp;&amp; &#40;hits &#43;&#61; 1&#41;
    end

    hits / N * &#40;b - a&#41; * fmax
end</code></pre><pre><code class="plaintext code-output">inthm</code></pre>
<p>Verifichiamo che il codice compili, e che produca un risultato sensato. Teniamo presente che \(\int_0^\pi \sin x\,\mathrm{d}x = 2\); inoltre, siccome \(\sin(x)\) è una funzione limitata in \([0, 1]\), possiamo porre <code>fmax&#61;1</code> nella chiamata a <code>inthm</code>:</p>
<pre><code class=language-julia >println&#40;&quot;Integrale &#40;metodo media&#41;:&quot;, intmean&#40;GLC&#40;1&#41;, sin, 0, π, 100&#41;&#41;
println&#40;&quot;Integrale &#40;metodo hit-or-miss&#41;:&quot;, inthm&#40;GLC&#40;1&#41;, sin, 0, π, 1, 100&#41;&#41;</code></pre><pre><code class="plaintext code-output">Integrale (metodo media):1.8715046084621125
Integrale (metodo hit-or-miss):1.9477874452256718
</code></pre>
<p>Implementate degli <code>assert</code> che verifichino che ottenete gli stessi risultati nella vostra implementazione C&#43;&#43;. Come già ricordato sopra, fate molta attenzione ad inizializzare il generatore di numeri pseudo-casuali con lo stesso seme &#40;<code>1</code> in questo caso&#41;.</p>
<p>Eseguiamo ora il calcolo per 10.000 volte e facciamone l&#39;istogramma: osserviamo che la distribuzione è approssimativamente una Gaussiana, come previsto.</p>
<pre><code class=language-julia >glc &#61; GLC&#40;1&#41;
mean_samples &#61; &#91;intmean&#40;glc, sin, 0, π, 100&#41; for i in 1:10_000&#93;
histogram&#40;mean_samples, label&#61;&quot;Media&quot;&#41;

glc &#61; GLC&#40;1&#41;  # Reset the random generator
mean_hm &#61; &#91;inthm&#40;glc, sin, 0, π, 1, 100&#41; for i in 1:10_000&#93;
histogram&#33;&#40;mean_hm, label&#61;&quot;Hit-or-miss&quot;&#41;</code></pre>
<img src="/tnds-notebooks/assets/lezione10/code/output/mc_integrals.svg" alt="">
<p>Se l&#39;andamento dell&#39;errore è della forma \(\epsilon(N) = k/\sqrt{N}\), con \(N\) numero di punti, allora nel nostro caso possiamo stimare \(k\) immediatamente dalla deviazione standard dei valori in <code>values</code> mediante la formula \(k =
\sqrt{N} \times \epsilon(N)\):</p>
<pre><code class=language-julia >k_mean &#61; √100 * std&#40;mean_samples&#41;
k_hm &#61; √100 * std&#40;mean_hm&#41;

println&#40;&quot;K &#40;media&#41; &#61; &quot;, k_mean&#41;
println&#40;&quot;K &#40;hit-or-miss&#41; &#61; &quot;, k_hm&#41;</code></pre><pre><code class="plaintext code-output">K (media) = 0.9574569402133133
K (hit-or-miss) = 1.4987026076211012
</code></pre>
<p>A questo punto, per rispondere alla domanda del problema, è sufficiente risolvere l&#39;equazione \(0.001 = k/\sqrt{N}\) per \(N\), ossia </p>
\[N =
\left(\frac{k}{0.001}\right)^2\]
<p>.</p>
<pre><code class=language-julia >noptim_mean &#61; round&#40;Int, &#40;k_mean/0.001&#41;^2&#41;
noptim_hm &#61; round&#40;Int, &#40;k_hm/0.001&#41;^2&#41;

println&#40;&quot;N &#40;media&#41; &#61; &quot;, noptim_mean&#41;
println&#40;&quot;N &#40;hit-or-miss&#41; &#61; &quot;, noptim_hm&#41;</code></pre><pre><code class="plaintext code-output">N (media) = 916724
N (hit-or-miss) = 2246110
</code></pre>
<p>Per verificare la correttezza del risultato, rifacciamo l&#39;istogramma. Siccome ci vuole molto tempo per ottenere il risultato, verifichiamo il risultato solo nel caso del metodo della media, e per un numero ridotto di realizzazioni &#40;1000 anziché 10.000&#41;:</p>
<pre><code class=language-julia >glc &#61; GLC&#40;1&#41;
values &#61; &#91;intmean&#40;glc, sin, 0, π, noptim_mean&#41; for i in 1:1000&#93;
histogram&#40;values, label&#61;&quot;&quot;&#41;</code></pre>
<img src="/tnds-notebooks/assets/lezione10/code/output/mc_intmean.svg" alt="">
<p>Il risultato è effettivamente corretto:</p>
<pre><code class=language-julia >std&#40;values&#41;</code></pre><pre><code class="plaintext code-output">0.001000082648024251</code></pre>
<h1 id=lezione_11_metodi_monte_carlo ><a href="#lezione_11_metodi_monte_carlo" class=header-anchor >Lezione 11: Metodi Monte Carlo</a></h1>
<h2 id=esercizio_110 ><a href="#esercizio_110" class=header-anchor >Esercizio 11.0</a></h2>
<p>Definiamo una serie di variabili per le costanti fisiche del problema:</p>
<pre><code class=language-julia >σ_θ &#61; 0.3e-3;
θ0_ref &#61; π / 2;
Aref &#61; 2.7;
Bref &#61; 60_000e-18;
α &#61; deg2rad&#40;60.0&#41;;
λ1 &#61; 579.1e-9;
λ2 &#61; 404.7e-9;</code></pre>
<p>La funzione <code>n_cauchy</code> restituisce \(n\) supponendo vera la formula di Cauchy. La sintassi con un parametro usa i valori di riferimento di \(A\) e \(B\) scritti sopra.</p>
<pre><code class=language-julia >n_cauchy&#40;λ, A, B&#41; &#61; sqrt&#40;A &#43; B / λ^2&#41;
n_cauchy&#40;λ&#41; &#61; n_cauchy&#40;λ, Aref, Bref&#41;</code></pre><pre><code class="plaintext code-output">n_cauchy (generic function with 2 methods)</code></pre>
<p>La funzione <code>n</code> invece restituisce \(n\) in funzione della deviazione misurata <code>δ</code> dal prisma, dove \(\alpha\) è il suo angolo di apertura &#40;definito sopra&#41;.</p>
<pre><code class=language-julia >n&#40;δ&#41; &#61; sin&#40;&#40;δ &#43; α&#41; / 2&#41; / sin&#40;α / 2&#41;
δ&#40;n&#41; &#61; 2asin&#40;n * sin&#40;α / 2&#41;&#41; - α</code></pre><pre><code class="plaintext code-output">δ (generic function with 1 method)</code></pre>
<p>Queste formule si ricavano banalmente dall&#39;inversione della formula di Cauchy; la funzione <code>A_and_B</code> calcola contemporaneamente \(A\) e \(B\), ed è stata definita per comodità:</p>
<pre><code class=language-julia >A&#40;λ1, δ1, λ2, δ2&#41; &#61; &#40;λ2^2 * n&#40;δ2&#41;^2 - λ1^2 * n&#40;δ1&#41;^2&#41; / &#40;λ2^2 - λ1^2&#41;
B&#40;λ1, δ1, λ2, δ2&#41; &#61; &#40;n&#40;δ2&#41;^2 - n&#40;δ1&#41;^2&#41; / &#40;1/λ2^2 - 1/λ1^2&#41;
A_and_B&#40;λ1, δ1, λ2, δ2&#41; &#61; &#40;A&#40;λ1, δ1, λ2, δ2&#41;, B&#40;λ1, δ1, λ2, δ2&#41;&#41;</code></pre><pre><code class="plaintext code-output">A_and_B (generic function with 1 method)</code></pre>
<p>Calcoliamo allora i valori di riferimento di \(n(\lambda_1) = n_1\) e \(n(\lambda_2) = n_2\), supponendo veri i valori di \(A\) e \(B\) scritti sopra r&#40;<code>A_ref</code> e <code>B_ref</code>&#41;:</p>
<pre><code class=language-julia >n1_ref, n2_ref &#61; n_cauchy&#40;λ1&#41;, n_cauchy&#40;λ2&#41;</code></pre><pre><code class="plaintext code-output">(1.6967362539886182, 1.751096919705952)</code></pre>
<p>Da \(n_1\) e \(n_2\) calcoliamo quanto aspettarci per \(\delta_1\) e \(\delta_2\):</p>
<pre><code class=language-julia >δ1_ref, δ2_ref &#61; δ&#40;n1_ref&#41;, δ&#40;n2_ref&#41;</code></pre><pre><code class="plaintext code-output">(0.9785928129680508, 1.0859421943701004)</code></pre>
<p>A questo punto possiamo simulare l&#39;esperimento. La simulazione della misura di \(\delta_1\) e \(\delta_2\) va fatta usando l&#39;approssimazione Gaussiana con i valori medi <code>δ1_ref</code> e <code>δ2_ref</code>, e la deviazione standard <code>σ_θ</code> data dal testo dell&#39;esercizio:</p>
<pre><code class=language-julia >function simulate_experiment&#40;glc, nsim&#41;
    n1_simul &#61; Array&#123;Float64&#125;&#40;undef, nsim&#41;
    n2_simul &#61; Array&#123;Float64&#125;&#40;undef, nsim&#41;

    A_simul &#61; Array&#123;Float64&#125;&#40;undef, nsim&#41;
    B_simul &#61; Array&#123;Float64&#125;&#40;undef, nsim&#41;

    for i in 1:nsim
        θ0 &#61; randgauss&#40;glc, θ0_ref, σ_θ&#41;
        θ1 &#61; randgauss&#40;glc, θ0_ref &#43; δ1_ref, σ_θ&#41;
        θ2 &#61; randgauss&#40;glc, θ0_ref &#43; δ2_ref, σ_θ&#41;
        δ1, δ2 &#61; θ1 - θ0, θ2 - θ0
        n1, n2 &#61; n&#40;δ1&#41;, n&#40;δ2&#41;
        a, b &#61; A_and_B&#40;λ1, δ1, λ2, δ2&#41;

        n1_simul&#91;i&#93; &#61; n1
        n2_simul&#91;i&#93; &#61; n2

        A_simul&#91;i&#93; &#61; a
        B_simul&#91;i&#93; &#61; b
    end

    &#40;n1_simul, n2_simul, A_simul, B_simul&#41;
end</code></pre><pre><code class="plaintext code-output">simulate_experiment (generic function with 1 method)</code></pre>
<p>Ecco i primi 5 valori della simulazione; controllate che siano gli stessi che ottenete voi, facendo attenzione di usare come seme <code>1</code> e che l&#39;ordine in cui chiamate la funzione per generare i numeri casuali sia la stessa del codice sopra:</p>
<ol>
<li><p><em>Prima</em> si genera \(\theta_0\);</p>

<li><p><em>Poi</em> si generano \(\theta_1\) e \(\theta_2\).</p>

</ol>
<p>Nel fare i plot qui sotto mi limito a ripetere l&#39;esperimento 1000 volte &#40;il testo richiede 10.000 volte&#41;. I risultati non cambiano molto.</p>
<pre><code class=language-julia >glc &#61; GLC&#40;1&#41;
n1_simul, n2_simul, A_simul, B_simul &#61; simulate_experiment&#40;glc, 1000&#41;

@printf&#40;&quot;&#37;14s &#37;14s &#37;14s &#37;14s\n&quot;, &quot;n₁&quot;, &quot;n₂&quot;, &quot;A&quot;, &quot;B&quot;&#41;
println&#40;repeat&#40;&#39;-&#39;, 62&#41;&#41;
for i &#61; 1:5
    # We use scientific notation for B, as it is ≪1
    @printf&#40;&quot;&#37;14.6f &#37;14.6f &#37;14.6f &#37;14.6e\n&quot;,
            n1_simul&#91;i&#93;, n2_simul&#91;i&#93;, A_simul&#91;i&#93;, B_simul&#91;i&#93;&#41;
end</code></pre><pre><code class="plaintext code-output">            n₁             n₂              A              B
--------------------------------------------------------------
      1.696732       1.751104       2.699946   6.001302e-14
      1.696576       1.751053       2.699084   6.012505e-14
      1.696956       1.751007       2.701759   5.966046e-14
      1.696639       1.750918       2.699958   5.990405e-14
      1.696847       1.751016       2.701005   5.978917e-14
</code></pre>
<pre><code class=language-julia >histogram&#40;&#91;n1_simul, n2_simul&#93;,
          label &#61; &#91;&quot;n₁&quot;, &quot;n₂&quot;&#93;,
          layout &#61; &#40;2, 1&#41;&#41;</code></pre>
<img src="/tnds-notebooks/assets/lezione10/code/output/hist_n1_n2.svg" alt="">
<pre><code class=language-julia >scatter&#40;n1_simul, n2_simul, label&#61;&quot;&quot;&#41;</code></pre>
<img src="/tnds-notebooks/assets/lezione10/code/output/scatter_n1_n2.svg" alt="">
<p>Il package <code>Statistics</code> di Julia implementa il calcolo della covarianza tra due serie, che è uguale alla correlazione a meno di una normalizzazione. Definiamo quindi la funzione <code>corr</code>, che calcola il coefficiente di correlazione, analogamente a questa; nel vostro codice C&#43;&#43; dovrete invece implementarla usando la formula.</p>
<pre><code class=language-julia >corr&#40;x, y&#41; &#61; cov&#40;x, y&#41; / &#40;std&#40;x&#41; * std&#40;y&#41;&#41;</code></pre><pre><code class="plaintext code-output">corr (generic function with 1 method)</code></pre>
<p>I valori di \(n_1\) ed \(n_2\) sono correlati, perché sono entrambi stati ricavati dalla medesima stima di \(\theta_0\).</p>
<pre><code class=language-julia >corr&#40;n1_simul, n2_simul&#41;</code></pre><pre><code class="plaintext code-output">0.4886624014617025</code></pre>
<p>Dal momento che \(B \ll 1\), applichiamo ad esso un fattore di scala \(10^{14}\):</p>
<pre><code class=language-julia >histogram&#40;&#91;A_simul, B_simul * 1e14&#93;,
          label &#61; &#91;&quot;A&quot; &quot;B × 10^14&quot;&#93;,
          layout &#61; &#40;2, 1&#41;&#41;</code></pre>
<img src="/tnds-notebooks/assets/lezione10/code/output/hist_A_B.svg" alt="">
<pre><code class=language-julia >scatter&#40;A_simul, B_simul * 1e14, label&#61;&quot;&quot;&#41;</code></pre>
<img src="/tnds-notebooks/assets/lezione10/code/output/scatter_A_B.svg" alt="">
<p>Ricalcoliamo qui i coefficienti di correlazione nel caso in cui l&#39;esperimento sia rifatto 10.000 volte. Notate che creo di nuovo un generatore di numeri casuali.</p>
<pre><code class=language-julia >glc &#61; GLC&#40;1&#41;
&#40;n1_simul, n2_simul, A_simul, B_simul&#41; &#61; simulate_experiment&#40;glc, 10_000&#41;
println&#40;&quot;Correlazione tra n1 e n2: &quot;, corr&#40;n1_simul, n2_simul&#41;&#41;
println&#40;&quot;Correlazione tra A e B: &quot;, corr&#40;A_simul, B_simul&#41;&#41;</code></pre><pre><code class="plaintext code-output">Correlazione tra n1 e n2: 0.5056534544299343
Correlazione tra A e B: -0.8682861987372525
</code></pre>
<h2 id=esercizio_111 ><a href="#esercizio_111" class=header-anchor >Esercizio 11.1</a></h2>
<p>L&#39;esercizio 11.1 è preso da un vecchio tema d&#39;esame, e va svolto in modo molto simile al precedente. Si tratta di misurare il coefficiente di viscosità \(\eta\) partendo dalla velocità di caduta di una sferetta di metallo all&#39;interno di un cilindro pieno di glicerina, tramite la formula </p>
\[ v_L =
\frac{2R^2}{9\eta}(\rho - \rho_0) g = \frac{\Delta x}{\Delta t}, \]
<p>dove \(\Delta x\) è la lunghezza del tratto percorso in caduta dalla sferetta e \(\Delta t\) il tempo impiegato. La relazione si inverte facilmente per dare </p>
\[
\eta = \frac{2R^2\,g\,\Delta t}{9\,\Delta x}(\rho - \rho_0), \]
<p>dove le quantità misurate in ognuno degli esperimenti Monte Carlo sono \(R\), \(\Delta x
= x_1 - x_0\), e \(\Delta t\).</p>
<p>Definiamo le costanti numeriche del problema, esprimendole tutte nel S.I. &#40;anche <code>x0</code>, <code>x1</code> e <code>Δx</code>&#33;&#41;</p>
<pre><code class=language-julia >δt, δx, δR &#61; 0.01, 0.001, 0.0001
ρ, ρ0 &#61; 2700.0, 1250.0
g &#61; 9.81
η_true &#61; 0.83
R_true &#61; Float64&#91;0.01, 0.005&#93;
x0 &#61; 0.2
x1 &#61; 0.6
Δx_true &#61; x1 - x0</code></pre><pre><code class="plaintext code-output">0.39999999999999997</code></pre>
<p>Definiamo anche alcune relazioni matematiche.</p>
<pre><code class=language-julia >v_L&#40;R, η&#41; &#61; 2R^2 / &#40;9η&#41; * &#40;ρ - ρ0&#41; * g
Δt&#40;R, Δx, η&#41; &#61; Δx / v_L&#40;R, η&#41;
Δt_true &#61; Float64&#91;Δt&#40;R, Δx_true, η_true&#41; for R in R_true&#93;
η&#40;R, Δt, Δx&#41; &#61; 2R^2 * g * Δt / &#40;9Δx&#41; * &#40;ρ - ρ0&#41;</code></pre><pre><code class="plaintext code-output">η (generic function with 1 method)</code></pre>
<p>Definiamo ora la funzione <code>simulate</code>, che effettua <em>due</em> esperimenti: uno con \(R = 0.01\,\text{m}\) e l&#39;altro con \(R = 0.005\,\text{m}\).</p>
<pre><code class=language-julia >function simulate&#40;glc::GLC, δx, δt, δR&#41;
    # Misura dell&#39;altezza iniziale
    cur_x0 &#61; randgauss&#40;glc, x0, δx&#41;
    # Misura dell&#39;altezza finale
    cur_x1 &#61; randgauss&#40;glc, x1, δx&#41;

    # Questo array di 2 elementi conterrà le due stime di η
    # &#40;corrispondenti ai due possibili raggi della sferetta&#41;
    estimated_η &#61; zeros&#40;2&#41;
    for case in &#91;1, 2&#93;
        # Misura delle dimensioni della sferetta
        cur_R &#61; randgauss&#40;glc, R_true&#91;case&#93;, δR&#41;
        cur_Δx &#61; cur_x1 - cur_x0

        # Misura del tempo necessario per cadere da cur_x0 a cur_x1
        cur_Δt &#61; randgauss&#40;glc, Δt_true&#91;case&#93;, δt&#41;

        # Stima di η
        estimated_η&#91;case&#93; &#61; η&#40;cur_R, cur_Δt, cur_Δx&#41;
    end

    estimated_η
end</code></pre><pre><code class="plaintext code-output">simulate (generic function with 1 method)</code></pre>
<p>Eseguiamo ora 1000 simulazioni e facciamo l&#39;istogramma della stima di \(\eta\) per i due raggi della sferetta.</p>
<pre><code class=language-julia >N &#61; 1_000
glc &#61; GLC&#40;1&#41;

η1 &#61; Array&#123;Float64&#125;&#40;undef, N&#41;
η2 &#61; Array&#123;Float64&#125;&#40;undef, N&#41;
for i in 1:N
    &#40;η1&#91;i&#93;, η2&#91;i&#93;&#41; &#61; simulate&#40;glc, δx, δt, δR&#41;
end

histogram&#40;η2, label&#61;@sprintf&#40;&quot;R &#61; &#37;.3f m&quot;, R_true&#91;2&#93;&#41;&#41;
histogram&#33;&#40;η1, label&#61;@sprintf&#40;&quot;R &#61; &#37;.3f m&quot;, R_true&#91;1&#93;&#41;&#41;</code></pre>
<img src="/tnds-notebooks/assets/lezione10/code/output/hist_eta1_eta2.svg" alt="">
<p>Si tratta ora di stimare le incertezze di \(\eta\) al variare degli errori considerati.</p>
<pre><code class=language-julia ># In η1 ed η2 abbiamo già le stime di η considerando tutti
# e tre gli errori
@printf&#40;&quot;Tutti gli errori: δη &#61; &#37;.4f kg/m/s &#40;R1&#41;\n&quot;, std&#40;η1&#41;&#41;
@printf&#40;&quot;                     &#61; &#37;.4f kg/m/s &#40;R2&#41;\n&quot;, std&#40;η2&#41;&#41;

# Ora dobbiamo eseguire di nuovo N esperimenti, assumendo che
# l&#39;errore sia presente in una sola delle tre quantità
for i in 1:N
    &#40;η1&#91;i&#93;, η2&#91;i&#93;&#41; &#61; simulate&#40;glc, 0.0, 0.0, δR&#41;
end
@printf&#40;&quot;Solo δR:          δη &#61; &#37;.4f kg/m/s &#40;R1&#41;\n&quot;, std&#40;η1&#41;&#41;
@printf&#40;&quot;                     &#61; &#37;.4f kg/m/s &#40;R2&#41;\n&quot;, std&#40;η2&#41;&#41;

# Idem
for i in 1:N
    &#40;η1&#91;i&#93;, η2&#91;i&#93;&#41; &#61; simulate&#40;glc, 0.0, δt, 0.0&#41;
end
@printf&#40;&quot;Solo δt:          δη &#61; &#37;.4f kg/m/s &#40;R1&#41;\n&quot;, std&#40;η1&#41;&#41;
@printf&#40;&quot;                     &#61; &#37;.4f kg/m/s &#40;R2&#41;\n&quot;, std&#40;η2&#41;&#41;

# Idem
for i in 1:N
    &#40;η1&#91;i&#93;, η2&#91;i&#93;&#41; &#61; simulate&#40;glc, δx, 0.0, 0.0&#41;
end
@printf&#40;&quot;Solo δx:          δη &#61; &#37;.4f kg/m/s &#40;R1&#41;\n&quot;, std&#40;η1&#41;&#41;
@printf&#40;&quot;                     &#61; &#37;.4f kg/m/s &#40;R2&#41;\n&quot;, std&#40;η2&#41;&#41;</code></pre><pre><code class="plaintext code-output">Tutti gli errori: δη = 0.0186 kg/m/s (R1)
                     = 0.0334 kg/m/s (R2)
Solo δR:          δη = 0.0160 kg/m/s (R1)
                     = 0.0327 kg/m/s (R2)
Solo δt:          δη = 0.0078 kg/m/s (R1)
                     = 0.0020 kg/m/s (R2)
Solo δx:          δη = 0.0028 kg/m/s (R1)
                     = 0.0028 kg/m/s (R2)
</code></pre>

<div class=page-foot >
  <div class=copyright >
    &copy; Maurizio Tomasi. Last modified: December 14, 2021. Website built with <a href="https://github.com/tlienart/Franklin.jl">Franklin.jl</a> and the <a href="https://julialang.org">Julia programming language</a>.
  </div>
</div>
</div>
    </div>  
    
        <script src="/tnds-notebooks/libs/katex/katex.min.js"></script>
<script src="/tnds-notebooks/libs/katex/auto-render.min.js"></script>
<script>renderMathInElement(document.body)</script>

    
    
        <script src="/tnds-notebooks/libs/highlight/highlight.pack.js"></script>
<script>hljs.initHighlightingOnLoad();hljs.configure({tabReplace: '    '});</script>